---
title: "The theory of the online update algorithms"
author: "Dawid Kałędkowski"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
 %\VignetteIndexEntry{The theory of the online update algorithms}
 %\VignetteEngine{knitr::rmarkdown}
 %\usepackage[utf8]{inputenc}
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

# Theory
Problem of sport matchups falls into subject of paired comparison modeling and 
choice modeling. Estimating player skills is equivalent to estimating preference 
of choice between two alternatives. Just as one product is more preferred over 
another to buy, similarly, better player is more preferred to win over worst. 
As player/event and alternative/experiment can be used interchangeably, for ease
of use sport nomenclature is adapted (player/event). 

Algorithms implemented in a `sport` package performs similarly, as all using 
Bayesian Approximation Method. Algorithms works as follows:
At some moment player `p` competes with player `q` while both have prior $R_p$ 
and $R_q$ ratings. Prior to event, probability that player `p` win over player 
`q` is $\hat{Y_{pq}}$. After event occurs, true result $Y_{pq}$ is observed, and
initial believes about rating is changed $R_p^{'} \leftarrow R_q$ according to 
the prediction error $(Y_{pq} - \hat{Y_{pq}} )$ and some constant $K$. Updates 
are summed as player can compete with more than one player in particular event.

$$\large R_p^{'} \leftarrow R_p + \sum_{q \neq p}{ K * (Y_{pq} - \hat{Y_{pq}}} )$$
Where: 
 $$\large \hat{Y} = P(X_i > X_j)$$ 
 $$K - learning rate$$

Outcome probability function is based on 
[Bradley-Terry model](https://en.wikipedia.org/wiki/Bradley%E2%80%93Terry_model) 
designed to predict outcome of pairwise comparison. For multi-player matchups 
where output is a ranking, `sport` package uses the same data transformation as
in [exploded logit](https://www.jstor.org/stable/270983) - ranking is then 
presented as combination of all possible pairs competing within same event.

## Glicko rating system
Glicko is the first bayesian online update algorithm incorporating rating 
volatility to rating and outcome computation. Glicko system is not balanced, and
sum of rating rewards of all players are not zero. In one 2-players event, 
reward of player `i` differs from reward of player `q` as it depends on their 
individual ratings deviation. Rating values oscillates around `r=1500` with max 
deviation `rd<=350`.

```{r message=FALSE, warning=FALSE}
library(sport)

# example taken from Glickman (1999)
data <- data.frame(id = 1, 
                   name = c("A", "B", "C", "D"), 
                   rank = c(3, 4, 1, 2))
r <- setNames(c(1500, 1400, 1550, 1700), c("A","B","C","D"))
rd <- setNames(c(200, 30, 100, 300), c("A","B","C","D"))

model <- glicko_run(rank | id ~ team(name), data = data, r = r, rd = rd)
print(model$final_r)

```

For deeper knowledge read 
[Mark E. Glickman (1999)](http://www.glicko.net/research/glicko.pdf).

Update Rules:

$$\hat{Y_{ij}} = P(X_i>X_j) = \frac{1}{ 1 + 10^{-g(RD_{ij}) * (R_i-R_j)/400}}$$

$${R'}_i = R_i + \frac{1}{\frac{1}{{RD}^2_{i}} + \frac{1}{d^2_i}} * \sum_j{g(RD_j) * (Y_{ij} - \hat{Y_{ij}}) }$$

$${RD'}_i = \sqrt{(\frac{1}{{RD}^2_{i}} + \frac{1}{d^2_i}})^{-1}$$

## Glicko2 rating system
Glicko2 improved predecessor by adding volatile parameter $\sigma_i$ which 
increase/decrease rating deviation in periods when player performance differs 
from expected. Sigma is estimated iteratively using Illinois algorithm, which 
converges quickly not affecting computation time. Rating values oscillates 
around `r=1500` with max deviation `rd<=350`.

```{r message=FALSE, warning=FALSE}
# example taken from Glickman (2013)
data <- data.frame(id = 1, 
                   name = c("A", "B", "C", "D"), 
                   rank = c(3, 4, 1, 2))
r <- setNames(c(1500, 1400, 1550, 1700), c("A","B","C","D"))
rd <- setNames(c(200, 30, 100, 300), c("A","B","C","D"))

model <- glicko2_run(rank | id ~ team(name), data = data, r = r, rd = rd)
print(model$final_r)

```

** write about modification of g_phi **

For further knowledge read 
[Mark E. Glickman (2013)](http://www.glicko.net/glicko/glicko2.pdf)

$$ \hat{Y_{ij}} = \frac{1}{1 + e^{-g(\phi_{ij})*(\mu_i - \mu_j)} }$$

$$ {\phi'}_i = \frac{1}{\sqrt{ \frac{1}{ { {\phi_i}^2 + {\sigma'_i}^2}} + \frac{1}{v} }}$$

$$ {\mu'_i} = \mu_i + {\phi'}_i * \sum_j{g(\phi_j)*(Y_{ij} - \hat{Y_{ij}})} $$


## Bayesian Bradley Terry
The fastest algorithm with simple formula. Original BT formula lacks variance 
parameter, and this method incorporates rating deviation into model. BBT also 
prevents against fast `rd` decline to zero using `gamma` and `kappa`.

For further knowledge read [Ruby C. Weng and Chih-Jen Lin (2011)](http://jmlr.csail.mit.edu/papers/volume12/weng11a/weng11a.pdf)

$$\hat{Y_{ij}} = P(X_i>X_j) = \frac{e^{R_i/c_{i_j}}}{e^{R_i/c_{ij}} + e^{R_j/c_{ij}}} $$

$${R'}_i = R_i + \sum_j{\frac{RD_i^2}{c_{ij}}*(Y_{ij} - \hat{Y_{ij}})}$$

$${RD'}_i = RD_i * [ 1 - \frac{RD_{ij}^2}{RD_i^2}\sum_j{ \gamma_j * (\frac{RD_i}{c_{ij}})^2* \hat{Y_{ij}}\hat{Y_{ji}} } ]$$



## Dynamic Bayesian Logit
Following algorithm gives some advantages over mentioned rating systems, adding 
other important factors to estimation process making final ratings unbiased. 
Algorithm perform better in disciples where other variables can make a 
difference in result eg. home field advantage. DBL implements Extended Kalman 
Filter learning rule, and allows to estimate multiple parameters in addition to
player ratings. DBL is a Dynamic Logit extended to usage in pairwise comparisons 
by modeling differences in players characteristics. Classic Bradley-Terry model 
is enriched by moderation element $K(s_t)$ which adds prior uncertainty to 
output prediction.

$$\hat{Y_{ij}} = \frac{ e^{-K(s_t)w _t^T(x_{it}-x_{jt})} }{1+e^{-K(s_t)w _t^T(x_{it}-x_{jt})}}$$
Parameters for player `i` competing with player `j` are estimated using EKF update rule.
$$\hat{\omega}_{it} = \hat{\omega}_{i(t-1)} + \frac{RD^2_{i(t-1)}}{1+\hat{Y_{ij}} (1-\hat{Y_{ij}})} x_t (Y_{ij} - \hat{Y_{ij}})$$
$$RD^2_{i t} = RD^2_{i(t-1)} - \frac{\hat{Y_{ij}}(1-\hat{Y_{ij}})}{1+\hat{Y_{ij}} (1-\hat{Y_{ij}})s_t^2}(RD^2_{i(t-1)}x_i)(RD^2_{i(t-1)}x_i)^T$$


For further knowledge read [Stephen J. Roberts, William Penny (2011)](https://www.researchgate.net/publication/2465226_Dynamic_Logistic_Regression)
